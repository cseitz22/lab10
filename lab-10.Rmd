---
title: "Lab 10 - Grading the professor, Pt. 2"
author: "Cat Seitz"
date: "03.09.2023"
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
library(broom)
```

```{r see-data}

evals<-evals

```


### Exercise 1

```{r fit-linear-model-beauty}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals) %>%
  tidy()

summary(lm(score ~ bty_avg, data = evals))

```

Model: (Evaluation Score) = 3.88 + 0.067(Beauty Rating)

The R2 was .035 and the adjusted R2 was .033

### Exercise 2

```{r multi-reg}

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + gender, data = evals) %>%
  tidy()

summary(lm(score ~ bty_avg + gender, data = evals))

```

Model: Evaluation Score = 3.75 + 0.074(Beauty Rating) + 0.17(Gender)

### Exercise 3

The evaluation score of a female with a beauty rating of 0 is 3.75. With each point increase in beauty rating, the model predicts a professor can add .074 points to their evaluation score. The model also predicts that males have evaluation scores .17 points higher than females. 

### Exercise 4

Roughly 5.5% of variability in the professors' evaluation scores is explained by the model. 

### Exercise 5

Line for just males: Evaluation score = 3.92 + 0.074(Beauty Rating)

### Exercise 6

Males tend to have higher evaluation scores given the same beauty rating. 

### Exercise 7



### Exercise 8 

The adjusted R2 increased by 0.022, suggesting gender is useful for explaining some of the variance in evaluation scores. 

### Exercise 9

The slope for m_bty_gen is higher than for m_bty, so adding gender to the model has changed the parameter estimate for the beuaty rating. 

### Exercise 10





